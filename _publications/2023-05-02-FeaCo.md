---
title: "FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions"
collection: publications
permalink: /publication/2023-05-02-FeaCo
excerpt: 'This paper is about the collaborative perception in noisy pose conditions.'
date: 2023-05-02
paperurl: '<br>https://dl.acm.org/doi/pdf/10.1145/3581783.3611880'
citation: '<br><b>Gu J</b>, Zhang J, Zhang M, et al. FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions[C]//Proceedings of the 31st ACM International Conference on Multimedia. 2023: 3628-3636.'
---

## Abstract

Collaborative perception offers a promising solution to overcome challenges such as occlusion and long-range data processing. However, limited sensor accuracy leads to noisy poses that misalign observations among vehicles. To address this problem, we propose the FeaCo, which achieves robust Feature-level Consensus among collaborating agents in noisy pose conditions without additional training. We design an efficient Pose-error Rectification Module (PRM) to align derived feature maps from different vehicles, reducing the adverse effect of noisy pose and bandwidth requirements. We also provide an effective multi-scale Cross-level Attention Module (CAM) to enhance information aggregation and interaction between various scales. Our FeaCo outperforms all other localization rectification methods, as validated on both the collaborative perception simulation dataset OPV2V and real-world dataset V2V4Real, reducing heading error and enhancing localization accuracy across various error levels.

## Problem Illustration

<div style="text-align: center;">
  <img src="https://jmgu0212.github.io/images/publications/FeaCo_View.png" width="40%">
</div>

The green vehicle and blue vehicle represent the ego AV and the CAV, respectively. If the pose of the CAV is incorrectly col- lected due to noise, the predicted position of the observed red vehicle will be biased. This inaccurate prediction can cause a collision between the ego AV and the observed vehicle.

## FeaCo: Pose-robust Feature-level Collaborative Framework

![FeaCo Overview](https://jmgu0212.github.io/images/publications/FeaCo_Overview.png)

After coarse-grained transformation, misaligned features are extracted by respective encoders and sent to Pose-Error Rectification Module (PRM) to generate fine-grained matrices for each CAV. Then, aligned features are derived by second transformation and aggregated through multi-scale fusion with Cross-level Attention Module (CAM). Through ego AV’s detection head, predictions are obtained and maintain precision and robustness in noisy pose conditions.

## Experiments Results

<!-- ![FeaCo Plot](https://jmgu0212.github.io/images/publications/FeaCo_Plot.png) -->

<div style="text-align: center;">
  <img src="https://jmgu0212.github.io/images/publications/FeaCo_Plot.png" width="40%">
</div>

<!-- <img src="https://jmgu0212.github.io/images/publications/FeaCo_Plot.png" width="30%"> -->

3D detection results on *OPV2V* dataset with various level of localization error. Results obtained by methods without robust designs are shown with dashed lines while results of methods with robust designs are shown in solid lines. Proposed method outperforms other methods with or without robust designs.

![FeaCo Result1](https://jmgu0212.github.io/images/publications/FeaCo_Result1.png)

<!-- <img src="https://jmgu0212.github.io/images/publications/FeaCo_Result1.png" width="90%"> -->

Following shows the 3D detection results in the Bird’s Eye View (BEV) format on the two subset of *OPV2V* dataset. Green and red boxes represent Ground Truth and prediction results, respectively. The similarity of these boxes reflects the performance of the testing methods. To assess the robustness of our FeaCo in high noise environments, the localization and heading error deviation is set to be 1.0.

![FeaCo Result2](https://jmgu0212.github.io/images/publications/FeaCo_Result2.png)

<!-- <img src="https://jmgu0212.github.io/images/publications/FeaCo_Result2.png" width="90%"> -->

Our PRM efficiently rectifies the pose error for a precise fusion process, while our multi-scale CAM ensures the performance of detecting vehicles at various distances. Our FeaCo effectively predicts vehicles in complex situations with high pose noise especially for localization error.


[Download paper here](https://dl.acm.org/doi/pdf/10.1145/3581783.3611880)

<!-- Recommended citation: **Gu J**, Zhang J, Zhang M, et al. FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions[C]//Proceedings of the 31st ACM International Conference on Multimedia. 2023: 3628-3636. -->

Recommended citation: 

```bibtex
@inproceedings{gu2023feaco,
  title={FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions},
  author={Gu, Jiaming and Zhang, Jingyu and Zhang, Muyang and Meng, Weiliang and Xu, Shibiao and Zhang, Jiguang and Zhang, Xiaopeng},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3628--3636},
  year={2023}
}
```

<!-- ---
title: "Paper Title Number 1"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2009-10-01
venue: 'Journal 1'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
This paper is about the number 1. The number 2 is left for future work.

[Download paper here](http://academicpages.github.io/files/paper1.pdf)

Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->