---
title: "FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions"
collection: publications
permalink: /publication/2023-05-02-FeaCo
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2023-05-02
paperurl: 'https://dl.acm.org/doi/pdf/10.1145/3581783.3611880'
citation: '<b>Gu J</b>, Zhang J, Zhang M, et al. FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions[C]//Proceedings of the 31st ACM International Conference on Multimedia. 2023: 3628-3636.'

codeurl: 'https://github.com/jmgu0212/FeaCo'
paperdata: 10/2023
paperYear: 2023
framework: 'https://media.springernature.com/full/springer-static/image/chp%3A10.1007%2F978-3-031-26313-2_13/MediaObjects/544766_1_En_13_Fig2_HTML.png?as=webp'
fast_read: 'To maintain the robustness of collaborative perception in noisy pose conditions, we propose FeaCo to help coarse-transformed representations reach Feature-level Consensus consistently. We design a simple but effective Pose-error Rectification Module(PRM) to align proposal matching regions more precisely. The use of a dense form of spatial confidence map further reduces redundancy and saves bandwidth. In the fusion stage, we provide a multi-scale Cross-level Attention Module (CAM) to enhance information aggregation and interaction between different scales. Experiments validate that our FeaCo outperforms other SOTA perception methods and maintains robustness in environments with various degrees of pose error.'
---

# Abstract
Collaborative perception offers a promising solution to overcome challenges such as occlusion and long-range data processing. However, limited sensor accuracy leads to noisy poses that misalign observations among vehicles. To address this problem, we propose the FeaCo, which achieves robust Feature-level Consensus among collaborating agents in noisy pose conditions without additional training. We design an efficient Pose-error Rectification Module (PRM) to align derived feature maps from different vehicles, reducing the adverse effect of noisy pose and bandwidth requirements. We also provide an effective multi-scale Cross-level Attention Module (CAM) to enhance information aggregation and interaction between various scales. Our FeaCo outperforms all other localization rectification methods, as validated on both the collaborative perception simulation dataset OPV2V and real-world dataset V2V4Real, reducing heading error and enhancing localization accuracy across various error levels.

[Download paper here](https://dl.acm.org/doi/pdf/10.1145/3581783.3611880)

Recommended citation: 
 ```bibtex
@inproceedings{gu2023feaco,
  title={FeaCo: Reaching Robust Feature-Level Consensus in Noisy Pose Conditions},
  author={Gu, Jiaming and Zhang, Jingyu and Zhang, Muyang and Meng, Weiliang and Xu, Shibiao and Zhang, Jiguang and Zhang, Xiaopeng},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3628--3636},
  year={2023}
}
```